{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('omw-1.4')\n",
    "# !mkdir /root/nltk_data/corpora\n",
    "# !cp ./wordnet.zip /root/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import  torch\n",
    "from torch import nn\n",
    "from transformers import get_scheduler\n",
    "import losses\n",
    "import data_load_utils\n",
    "import random\n",
    "from Configs import Config\n",
    "from model import Imporved_BRIO\n",
    "import SELECT_MODEL_AND_DATASET\n",
    "import time\n",
    "from TestDataSet import ValidDataSet\n",
    "from compare_mt.rouge.rouge_scorer import RougeScorer\n",
    "rouge_scorer = RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "model_size  = 'large'\n",
    "model_name = 'pegasus'\n",
    "dataset_name = 'xsum'\n",
    "is_model_base =  True if model_size == 'base' else False\n",
    "args = Config(data_name=dataset_name)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "LOSS_DIR = f'./loss_res-{dataset_name}'\n",
    "CHECK_POINTS_DIR = './check_points'\n",
    "\n",
    "if(not os.path.exists(LOSS_DIR)):\n",
    "    os.mkdir(LOSS_DIR)\n",
    "if(not os.path.exists(CHECK_POINTS_DIR)):\n",
    "    os.mkdir(CHECK_POINTS_DIR)\n",
    "\n",
    "def flush_res(text):\n",
    "    with open('./pred_text.txt','w') as f:\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "def flush_mle(text):\n",
    "    with open(os.path.join(LOSS_DIR,'mle_loss.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "        \n",
    "def flush_contraste(text):\n",
    "    with open(os.path.join(LOSS_DIR,'contraste_loss.txt'),'a+') as f:\n",
    "        f.write(text+ '\\n')\n",
    "        f.close()\n",
    "def flush_loss(text):\n",
    "    with open(os.path.join(LOSS_DIR,'loss.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "def flush_acc_rank(text):\n",
    "    with open(os.path.join(LOSS_DIR,'acc_rank_loss.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "def flush_ce(text):\n",
    "    with open(os.path.join(LOSS_DIR,'ce_loss.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "def flush_acc(text):\n",
    "    with open(os.path.join(LOSS_DIR,'acc.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "def flush_lp(text):\n",
    "    with open(os.path.join(LOSS_DIR,'lp_loss.txt'),'a+') as f:\n",
    "        f.write(text+'\\n')\n",
    "        f.close()\n",
    "def flush_val_rouge(text):\n",
    "    with open(os.path.join(LOSS_DIR,'val_rouge.txt'),'a+') as f:\n",
    "        f.write(text+' ')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Imporved_BRIO(model_name=model_name,dataset_name=dataset_name,args = args).to(args.device)\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = data_load_utils.BrioDataset(fdir=args.candidates_train_dir,tokenizer = tokenizer,max_len = args.max_len,total_len = args.total_len,is_pegasus = args.is_pegasus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.6, 4, 512, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.is_pegasus,args.length_penalty,args.accumulate_step,args.total_len,args.val_size,args.mle_weight,args.contraste_weight,args.margin,args.gold_margin,args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "collate_fn = partial(data_load_utils.collate_mp_brio, pad_token_id=tokenizer.pad_token_id, is_test=False)\n",
    "train_loader = DataLoader(train_set,batch_size = args.batch_size,shuffle=True,drop_last=True,collate_fn=collate_fn)\n",
    "validation_set = ValidDataSet('./xsum_validation_set/',l = args.val_size)\n",
    "validation_loader =DataLoader(dataset=validation_set,batch_size=args.val_size,shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 10, 0.001, 0, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "def validation(model,args):\n",
    "    scores = 0\n",
    "    for data in validation_loader:\n",
    "        if dataset_name == 'cnndam':\n",
    "            x = [ i.lower().strip() for i in data[0]]\n",
    "            y = [ i.lower().strip() for i in data[1]]\n",
    "        else:\n",
    "            x = [ i.strip() for i in data[0]]\n",
    "            y = [ i.strip() for i in data[1]]\n",
    "        pred_list=[]\n",
    "        X = tokenizer.batch_encode_plus(x, max_length=args.total_len, truncation=True, return_tensors='pt',padding='max_length').to(args.device)\n",
    "        with torch.no_grad():\n",
    "            out = model.model.generate(\n",
    "                input_ids=X.input_ids.to(args.device),\n",
    "                attention_mask=X.attention_mask.to(args.device),\n",
    "                max_length = args.gen_max_len + 2,\n",
    "                min_length=args.gen_min_len + 1,\n",
    "                no_repeat_ngram_size=3,\n",
    "                early_stopping=True,\n",
    "                num_beams=4\n",
    "            )\n",
    "        pred = tokenizer.batch_decode(out,skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if dataset_name == 'cnndam':\n",
    "            pred =[i.lower().strip() for i in pred]\n",
    "        else :\n",
    "            pred =[i.strip() for i in pred]\n",
    "        break\n",
    "    n = len(pred)\n",
    "    for  i in range(n):\n",
    "        rouge = rouge_scorer.score(target=y[i],prediction=pred[i])\n",
    "        scores+= rouge['rouge1'].fmeasure\n",
    "    scores = scores / n\n",
    "    del x,y,pred_list,X,out,pred\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/generation_utils.py:1818: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    }
   ],
   "source": [
    "mle_fn = losses.label_smooth_loss(tokenizer.pad_token_id,epsilon=args.smooth)\n",
    "flush_step = 50\n",
    "mle_list ,ce_list,contraste_list,loss_list,acc_rank_list,ce_list,acc_list ,lp_list= [],[],[],[],[],[],[],[]\n",
    "all_step_cnt = 0\n",
    "\n",
    "for epoch in range(1,args.epoch+1):\n",
    "    t1  = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    step_cnt = 0\n",
    "    z=0\n",
    "    for i , batch in enumerate(train_loader):\n",
    "        \n",
    "        step_cnt += 1\n",
    "        model.train()\n",
    "        x = batch[\"src_input_ids\"].to(args.device)\n",
    "        y =  batch[\"candidate_ids\"].to(args.device)\n",
    "        output,candidate_id,cand_mask,all_prob = model(x, y, normalize=args.normalize, score_mode='log', length_penalty=args.length_penalty, require_gold=True, adding=0)\n",
    "        similarity, gold_similarity = output['score'].to(args.device), output['summary_score'].to(args.device)\n",
    "        similarity = similarity * args.scale\n",
    "        gold_similarity = gold_similarity * args.scale\n",
    "        contraste_loss = losses.RankingLoss(similarity, gold_similarity, args.margin, args.gold_margin, args.gold_weight)\n",
    "        probs = output[\"probs\"].to(args.device)  # [bz, seq_len, word_num]\n",
    "        probs = output[\"probs\"][:, :-1]  # truncate last token\n",
    "        gold = batch[\"candidate_ids\"][:, 0, 1:].to(args.device)  # shift right\n",
    "        mle_loss = mle_fn(probs.transpose(1, 2), gold)\n",
    "        \n",
    "        acc_rank_loss ,acc,lp_loss= losses.acc_rankling_loss(all_prob,candidate_id,cand_mask,lenth_penalty=args.length_penalty,is_lpsum=args.is_lpsum)\n",
    "        loss = args.contraste_weight* contraste_loss +  args.mle_weight*mle_loss  +args.lp_weight *lp_loss + args.acc_rank_weight * acc_rank_loss\n",
    "        mle_list.append(mle_loss.item())\n",
    "        contraste_list.append(contraste_loss.item())\n",
    "        loss_list.append(loss.item())\n",
    "        acc_rank_list.append(acc_rank_loss.item())\n",
    "        lp_list.append(lp_loss.item())\n",
    "        acc_list .append(acc.item())\n",
    "        \n",
    "        if(i % flush_step == 0 and i > 0):\n",
    "            flush_loss(str(sum(loss_list) / flush_step))\n",
    "            flush_mle(str(sum(mle_list) / flush_step))\n",
    "            flush_contraste(str(sum(contraste_list) / flush_step))\n",
    "            flush_acc_rank(str(sum(acc_rank_list) / flush_step))\n",
    "            flush_lp(str(sum(lp_list) / flush_step))\n",
    "            flush_acc(str(sum(acc_list) / flush_step))\n",
    "            mle_list.clear()\n",
    "            contraste_list.clear()\n",
    "            loss_list.clear()\n",
    "            acc_rank_list.clear()\n",
    "            lp_list.clear()\n",
    "            acc_list.clear()\n",
    "        loss = loss / args.accumulate_step\n",
    "        loss.backward()\n",
    "            \n",
    "        if (step_cnt == args.accumulate_step):\n",
    "            if args.grad_norm > 0:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), args.grad_norm)\n",
    "            step_cnt = 0\n",
    "            all_step_cnt += 1\n",
    "            # adjust learning rate\n",
    "            lr = args.max_lr * min(all_step_cnt ** (-0.5), all_step_cnt * (args.warmup_steps ** (-1.5)))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        if(i%10 == 0):\n",
    "            t2 = time.time()\n",
    "            t = int(t2 - t1)\n",
    "            flush_res(f'{epoch}:[{str(i)}/{len(train_loader)}]:{loss.item()}\\n[10 items / {t}s]')\n",
    "            t1 = time.time()\n",
    "\n",
    "        del similarity, gold_similarity, loss, mle_loss, output, probs,acc_rank_loss,acc,contraste_loss,lp_loss\n",
    "        if(i % 20 ==0):\n",
    "            model.eval()\n",
    "            val_rouge = validation(model,args)\n",
    "            if(val_rouge) >= args.stand_rouge: \n",
    "                model_save_name = f'based_on-{model_name}-{dataset_name}-{epoch}-{i}-rouge-{val_rouge}-.bin'\n",
    "                dirs_ = [ f for f in os.listdir(CHECK_POINTS_DIR) if f.endswith('.bin')]\n",
    "                if(len(dirs_) >12):\n",
    "                    dirs = [f.split('-') for f in dirs_]\n",
    "                    rouge_number = [float(n[6]) for n in dirs]\n",
    "                    v_r = float(model_save_name.split('-')[6])\n",
    "                    if(v_r >= min(rouge_number)):\n",
    "                        dirs.sort(key=lambda x:x[6],reverse=False)\n",
    "                        t_name = dirs[0][6]\n",
    "                        for i in dirs_:\n",
    "                            if (i.__contains__(t_name)):\n",
    "                                os.remove(os.path.join(CHECK_POINTS_DIR,i))\n",
    "                                torch.save(model,os.path.join(CHECK_POINTS_DIR,model_save_name))\n",
    "                                break\n",
    "                else:\n",
    "                    torch.save(model,os.path.join(CHECK_POINTS_DIR,model_save_name))\n",
    "                                           \n",
    "                \n",
    "            model.train()\n",
    "            if(z%40 ==0):\n",
    "                flush_val_rouge(str(val_rouge))\n",
    "        z+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}